{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import csv\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the json from mongo-db onto a list of OrderedDict objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mongodb-documents.json\",\"r\") as f:\n",
    "    dic = json.load(f)\n",
    "\n",
    "#pprint.pprint(dic, indent=2) # all different kind of publications are in an array marked by the key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracts the relations from the json\n",
    "in particular:\n",
    "-publications to authors\n",
    "-publications to keywords\n",
    "-citations\n",
    "creates the authors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all useful relations: authors, editors and ee\n",
    "def flatten(l):\n",
    "    if isinstance(l, list):\n",
    "        return [subelem for elem in l for subelem in flatten(elem)]\n",
    "    else:\n",
    "        return [l]\n",
    "\n",
    "def normalize_item(elem, args):\n",
    "    ret_val =   tuple(elem[arg] for arg in args)\\\n",
    "                if isinstance(elem, collections.OrderedDict)\\\n",
    "                and set(args).issubset(elem.keys())\\\n",
    "                else tuple(\n",
    "                    [elem] + [None for arg in range(len(args) - 1)]\n",
    "                    )\n",
    "    return ret_val[0] if len(ret_val) == 1 else ret_val\n",
    "\n",
    "def extract_one_to_many_relation(collection_in_use, first_arg, second_arg, normalize=False, normalizing_params=[]):\n",
    "    ret_val = [(pub[first_arg], pub[second_arg]) for pub in collection_in_use if second_arg in pub.keys()]\n",
    "    return [(key, normalize_item(item, normalizing_params) if normalize is True else item)\\\n",
    "            for key,val in ret_val\\\n",
    "            for item in flatten(val)]\n",
    "\n",
    "pub_to_authors = extract_one_to_many_relation(dic, \"title\", \"authors\")\n",
    "pub_to_keywords = extract_one_to_many_relation(dic, \"title\", \"keywords\")\n",
    "citations = extract_one_to_many_relation(dic, \"title\", \"citations\")\n",
    "\n",
    "temp_authors = list(val[1] for val in pub_to_authors)\n",
    "authors_names = set()\n",
    "authors = []\n",
    "for val in temp_authors:\n",
    "    if val[\"name\"] not in authors_names:\n",
    "        authors.append(val)\n",
    "        authors_names.add(val[\"name\"])\n",
    "#leave only the name of the authors in the relation as 2nd key\n",
    "pub_to_authors = list(map(lambda rel: (rel[0], rel[1][\"name\"]), pub_to_authors))\n",
    "\n",
    "\n",
    "#pprint.pprint(pub_to_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casts the values of year to int insted of string\n",
    "#removes \\n charachters from bio\n",
    "\n",
    "for auth in authors:\n",
    "    auth[\"birth_year\"] = int(auth[\"birth_year\"]) if \"birth_year\" in auth.keys() else 1900\n",
    "    auth[\"bio\"] = auth[\"bio\"].replace(\"\\n\",\" \") if \"bio\" in auth.keys() else None\n",
    "#pprint.pprint(authors, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create publications and authors tables\n",
    "def make_publication_csv_compliant(publication, args):\n",
    "    return tuple(publication[arg] if arg in publication.keys() else None for arg in args)\n",
    "def map_to_csv(collection_in_use, args):\n",
    "    return list(map(lambda x: make_publication_csv_compliant(x, args), collection_in_use))\n",
    "pub_params = [\"title\", \"type\",\"publisher\",\"journal\", \"month\", \"year\", \"language\", \"booktitle\", \"volume\", \"pages\", \"ee\"]\n",
    "pub_csv = map_to_csv(dic, pub_params)\n",
    "\n",
    "auth_params = [\"name\", \"birth_year\", \"email\", \"affiliations\", \"bio\"]\n",
    "auth_csv = map_to_csv(authors, auth_params)\n",
    "#pprint.pprint(auth_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with publications.csv! (num of elements was: 2000)\n",
      "done with authors.csv! (num of elements was: 1134)\n",
      "done with publications2authors.csv! (num of elements was: 2406)\n",
      "done with citations.csv! (num of elements was: 20227)\n",
      "done with keywords.csv! (num of elements was: 4060)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#loads everything onto their csvs\n",
    "CSVs_to_make = [\n",
    "    (\"publications\",pub_params, pub_csv),\n",
    "    (\"authors\", auth_params, auth_csv),\n",
    "    (\"publications2authors\", [\"title\",\"auth_name\"], pub_to_authors),\n",
    "    (\"citations\", [\"citing\", \"cited\"], citations),\n",
    "    (\"keywords\", [\"title\", \"keyword\"], pub_to_keywords)\n",
    "]\n",
    "dir_path = os.path.abspath(\"\") + os.sep + \"data\"\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    print(\"directory added\")\n",
    "for table in CSVs_to_make:\n",
    "    path_of_file = dir_path + os.sep + table[0] + \".csv\"\n",
    "    with open(path_of_file, \"w\") as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerow(table[1])\n",
    "        writer.writerows(table[2])\n",
    "    print(f\"done with {table[0]}.csv! (num of elements was: {len(table[2])})\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
